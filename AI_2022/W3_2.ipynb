{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba6e346",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-18T02:42:26.017224Z",
     "iopub.status.busy": "2022-09-18T02:42:26.016406Z",
     "iopub.status.idle": "2022-09-18T02:42:26.029278Z",
     "shell.execute_reply": "2022-09-18T02:42:26.028359Z"
    },
    "papermill": {
     "duration": 0.020804,
     "end_time": "2022-09-18T02:42:26.031724",
     "exception": false,
     "start_time": "2022-09-18T02:42:26.010920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/2022-ai-w3p2/train_data.csv\n",
      "/kaggle/input/2022-ai-w3p2/test_data.csv\n",
      "/kaggle/input/2022-ai-w3p2/sample_submit.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ed73f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:42:26.038647Z",
     "iopub.status.busy": "2022-09-18T02:42:26.037791Z",
     "iopub.status.idle": "2022-09-18T02:42:26.104943Z",
     "shell.execute_reply": "2022-09-18T02:42:26.104039Z"
    },
    "papermill": {
     "duration": 0.07277,
     "end_time": "2022-09-18T02:42:26.107252",
     "exception": false,
     "start_time": "2022-09-18T02:42:26.034482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/2022-ai-w3p2/train_data.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/2022-ai-w3p2/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e942b3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:42:26.114603Z",
     "iopub.status.busy": "2022-09-18T02:42:26.113670Z",
     "iopub.status.idle": "2022-09-18T02:42:26.959581Z",
     "shell.execute_reply": "2022-09-18T02:42:26.958550Z"
    },
    "papermill": {
     "duration": 0.852048,
     "end_time": "2022-09-18T02:42:26.962178",
     "exception": false,
     "start_time": "2022-09-18T02:42:26.110130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>engineSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3764</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>27056</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>60.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3375</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>5743</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>47.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>32782</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17080</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>4666</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>32.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17081</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>22601</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>39.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17082</th>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>20312</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>47.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17083</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>18695</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>58.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17084</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>37812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.4</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17085 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       company  model  year  transmission  mileage  fueltype  tax   mpg  \\\n",
       "0            2     26  2019             1     3764         4  145  34.5   \n",
       "1            1     34  2015             1    27056         4   20  60.1   \n",
       "2            3      9  2019             3     3375         4  145  34.5   \n",
       "3            3     12  2019             0     5743         0  145  47.9   \n",
       "4            2     25  2015             1    32782         4    0  65.7   \n",
       "...        ...    ...   ...           ...      ...       ...  ...   ...   \n",
       "17080        0      0  2018             0     4666         4  145  32.5   \n",
       "17081        3     10  2020             3    22601         4  145  39.2   \n",
       "17082        4     93  2018             1    20312         4  145  47.1   \n",
       "17083        2     26  2018             1    18695         4  145  58.9   \n",
       "17084        2     25  2014             1    37812         0    0  76.4   \n",
       "\n",
       "       engineSize  \n",
       "0             2.3  \n",
       "1             1.0  \n",
       "2             2.0  \n",
       "3             2.0  \n",
       "4             1.0  \n",
       "...           ...  \n",
       "17080         3.0  \n",
       "17081         2.0  \n",
       "17082         1.5  \n",
       "17083         1.0  \n",
       "17084         1.5  \n",
       "\n",
       "[17085 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cls = LabelEncoder()\n",
    "train_data['model'] = cls.fit_transform(train_data['model'].values)\n",
    "test_data['model'] = cls.fit_transform(test_data['model'].values)\n",
    "\n",
    "train_y = train_data['price']\n",
    "train_x = train_data.drop(['ID', 'price'], axis = 1)\n",
    "test_x = test_data.drop('ID', axis = 1)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183ba79c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:42:26.970171Z",
     "iopub.status.busy": "2022-09-18T02:42:26.969840Z",
     "iopub.status.idle": "2022-09-18T02:42:28.503547Z",
     "shell.execute_reply": "2022-09-18T02:42:28.502354Z"
    },
    "papermill": {
     "duration": 1.540176,
     "end_time": "2022-09-18T02:42:28.505845",
     "exception": false,
     "start_time": "2022-09-18T02:42:26.965669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26299.,  5495., 32400.,  ..., 10950., 13295.,  7299.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "x_train = torch.FloatTensor(train_x.values)\n",
    "x_test = torch.FloatTensor(test_x.values)\n",
    "y_train = torch.FloatTensor(train_y.values)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1d645e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:42:28.513663Z",
     "iopub.status.busy": "2022-09-18T02:42:28.513204Z",
     "iopub.status.idle": "2022-09-18T02:42:28.521646Z",
     "shell.execute_reply": "2022-09-18T02:42:28.520379Z"
    },
    "papermill": {
     "duration": 0.014427,
     "end_time": "2022-09-18T02:42:28.523629",
     "exception": false,
     "start_time": "2022-09-18T02:42:28.509202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26299.],\n",
       "        [ 5495.],\n",
       "        [32400.],\n",
       "        ...,\n",
       "        [10950.],\n",
       "        [13295.],\n",
       "        [ 7299.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.view([-1, 1])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927dd860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:42:28.532129Z",
     "iopub.status.busy": "2022-09-18T02:42:28.530721Z",
     "iopub.status.idle": "2022-09-18T02:48:39.344368Z",
     "shell.execute_reply": "2022-09-18T02:48:39.342814Z"
    },
    "papermill": {
     "duration": 370.819731,
     "end_time": "2022-09-18T02:48:39.346514",
     "exception": false,
     "start_time": "2022-09-18T02:42:28.526783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000000 hypothesis: tensor([0., 0., 0.,  ..., 0., 0., 0.]) Cost: 16819.765625\n",
      "Epoch 10000/1000000 hypothesis: tensor([17921.6875, 14360.9756, 17972.1191,  ..., 15626.7754, 15836.2754,\n",
      "        12808.4990]) Cost: 6247.862793\n",
      "Epoch 20000/1000000 hypothesis: tensor([17934.6934, 14205.9873, 17983.4980,  ..., 15672.7920, 15871.9199,\n",
      "        12636.8662]) Cost: 6218.888672\n",
      "Epoch 30000/1000000 hypothesis: tensor([17969.9512, 14053.5879, 18017.7363,  ..., 15719.4668, 15910.8271,\n",
      "        12455.8047]) Cost: 6192.662109\n",
      "Epoch 40000/1000000 hypothesis: tensor([18002.4160, 13903.0908, 18049.3828,  ..., 15760.5156, 15945.0020,\n",
      "        12276.5801]) Cost: 6168.451172\n",
      "Epoch 50000/1000000 hypothesis: tensor([18029.6758, 13771.3262, 18075.6953,  ..., 15807.2129, 15984.3604,\n",
      "        12124.8994]) Cost: 6146.175293\n",
      "Epoch 60000/1000000 hypothesis: tensor([18064.9121, 13650.1865, 18110.1875,  ..., 15857.2451, 16027.9727,\n",
      "        11982.5928]) Cost: 6125.946289\n",
      "Epoch 70000/1000000 hypothesis: tensor([18069.4297, 13518.2412, 18113.8398,  ..., 15885.6416, 16049.5049,\n",
      "        11836.7871]) Cost: 6107.157715\n",
      "Epoch 80000/1000000 hypothesis: tensor([18109.4941, 13391.8613, 18153.6484,  ..., 15923.8115, 16083.4023,\n",
      "        11680.8477]) Cost: 6089.750488\n",
      "Epoch 90000/1000000 hypothesis: tensor([18136.0898, 13270.1797, 18179.8047,  ..., 15956.5000, 16111.1553,\n",
      "        11535.9727]) Cost: 6073.757324\n",
      "Epoch 100000/1000000 hypothesis: tensor([18154.2305, 13164.5625, 18197.3008,  ..., 15992.5664, 16141.4941,\n",
      "        11416.3350]) Cost: 6059.232910\n",
      "Epoch 110000/1000000 hypothesis: tensor([18179.8672, 13052.8994, 18222.6719,  ..., 16021.2051, 16166.0508,\n",
      "        11282.2529]) Cost: 6046.070801\n",
      "Epoch 120000/1000000 hypothesis: tensor([18228.8242, 12974.0771, 18271.3535,  ..., 16074.8447, 16215.6582,\n",
      "        11183.3809]) Cost: 6034.177734\n",
      "Epoch 130000/1000000 hypothesis: tensor([18261.0703, 12895.3711, 18303.1855,  ..., 16119.1309, 16255.4014,\n",
      "        11090.5674]) Cost: 6023.364746\n",
      "Epoch 140000/1000000 hypothesis: tensor([18273.9180, 12785.7578, 18315.9844,  ..., 16131.1299, 16264.4404,\n",
      "        10959.7314]) Cost: 6013.625000\n",
      "Epoch 150000/1000000 hypothesis: tensor([18314.0215, 12743.1162, 18355.5332,  ..., 16193.6387, 16321.9482,\n",
      "        10912.2354]) Cost: 6004.745117\n",
      "Epoch 160000/1000000 hypothesis: tensor([18336.6152, 12663.5107, 18378.0312,  ..., 16220.8721, 16346.1543,\n",
      "        10817.2627]) Cost: 5996.747559\n",
      "Epoch 170000/1000000 hypothesis: tensor([18363.7148, 12597.7354, 18405.0566,  ..., 16254.1328, 16376.5215,\n",
      "        10738.4307]) Cost: 5989.667969\n",
      "Epoch 180000/1000000 hypothesis: tensor([18388.5527, 12542.3096, 18429.7285,  ..., 16289.8477, 16409.0293,\n",
      "        10674.0576]) Cost: 5983.359375\n",
      "Epoch 190000/1000000 hypothesis: tensor([18403.7520, 12453.3994, 18445.2910,  ..., 16294.8604, 16413.0996,\n",
      "        10563.5635]) Cost: 5977.766602\n",
      "Epoch 200000/1000000 hypothesis: tensor([18435.2930, 12414.4561, 18476.7734,  ..., 16336.2871, 16451.8867,\n",
      "        10517.0977]) Cost: 5972.697754\n",
      "Epoch 210000/1000000 hypothesis: tensor([18468.0312, 12370.2031, 18509.6953,  ..., 16370.5664, 16484.5703,\n",
      "        10460.8799]) Cost: 5968.205078\n",
      "Epoch 220000/1000000 hypothesis: tensor([18497.9941, 12330.4961, 18539.7812,  ..., 16404.1484, 16516.3770,\n",
      "        10411.2734]) Cost: 5964.160645\n",
      "Epoch 230000/1000000 hypothesis: tensor([18510.1230, 12294.9033, 18551.7461,  ..., 16432.3945, 16541.6934,\n",
      "        10374.6406]) Cost: 5960.507812\n",
      "Epoch 240000/1000000 hypothesis: tensor([18530.5137, 12262.1338, 18572.1328,  ..., 16462.2891, 16569.3477,\n",
      "        10337.1719]) Cost: 5957.225098\n",
      "Epoch 250000/1000000 hypothesis: tensor([18556.8457, 12218.0068, 18598.8418,  ..., 16483.1250, 16589.6074,\n",
      "        10279.3271]) Cost: 5954.274902\n",
      "Epoch 260000/1000000 hypothesis: tensor([18581.7598, 12179.4697, 18624.1191,  ..., 16505.0254, 16610.8789,\n",
      "        10229.3672]) Cost: 5951.582031\n",
      "Epoch 270000/1000000 hypothesis: tensor([18598.8848, 12128.2861, 18641.7246,  ..., 16513.0352, 16618.8203,\n",
      "        10163.3652]) Cost: 5949.208984\n",
      "Epoch 280000/1000000 hypothesis: tensor([18612.6895, 12100.4736, 18655.6465,  ..., 16534.1445, 16638.3672,\n",
      "        10132.0459]) Cost: 5947.044922\n",
      "Epoch 290000/1000000 hypothesis: tensor([18617.9297, 12057.7969, 18661.1680,  ..., 16540.3711, 16643.7598,\n",
      "        10082.2402]) Cost: 5945.069336\n",
      "Epoch 300000/1000000 hypothesis: tensor([18637.4766, 12026.6357, 18681.1094,  ..., 16556.9023, 16659.9590,\n",
      "        10041.8662]) Cost: 5943.286133\n",
      "Epoch 310000/1000000 hypothesis: tensor([18658.2793, 12001.0332, 18702.3164,  ..., 16575.4023, 16678.1953,\n",
      "        10008.1299]) Cost: 5941.688477\n",
      "Epoch 320000/1000000 hypothesis: tensor([18668.1797, 11966.3408, 18712.6699,  ..., 16582.3340, 16685.0840,\n",
      "         9965.4023]) Cost: 5940.239258\n",
      "Epoch 330000/1000000 hypothesis: tensor([18681.9473, 11946.6592, 18726.7441,  ..., 16599.3457, 16701.4883,\n",
      "         9942.1357]) Cost: 5938.926270\n",
      "Epoch 340000/1000000 hypothesis: tensor([18690.5371, 11924.0186, 18735.6660,  ..., 16610.9238, 16712.5742,\n",
      "         9916.2119]) Cost: 5937.729004\n",
      "Epoch 350000/1000000 hypothesis: tensor([18691.6328, 11889.3682, 18737.1973,  ..., 16610.5820, 16712.1699,\n",
      "         9875.6660]) Cost: 5936.612305\n",
      "Epoch 360000/1000000 hypothesis: tensor([18700.2715, 11866.8105, 18746.2344,  ..., 16619.2793, 16720.6836,\n",
      "         9848.5918]) Cost: 5935.617676\n",
      "Epoch 370000/1000000 hypothesis: tensor([18702.9355, 11842.8555, 18749.2695,  ..., 16623.9668, 16725.0996,\n",
      "         9821.7490]) Cost: 5934.704590\n",
      "Epoch 380000/1000000 hypothesis: tensor([18713.4395, 11829.2500, 18760.1094,  ..., 16637.6348, 16738.3730,\n",
      "         9806.1357]) Cost: 5933.842773\n",
      "Epoch 390000/1000000 hypothesis: tensor([18719.0527, 11808.0586, 18766.1289,  ..., 16643.1191, 16743.7793,\n",
      "         9781.0996]) Cost: 5933.050781\n",
      "Epoch 400000/1000000 hypothesis: tensor([18724.8848, 11780.6396, 18772.5234,  ..., 16642.5352, 16743.7930,\n",
      "         9746.1670]) Cost: 5932.339355\n",
      "Epoch 410000/1000000 hypothesis: tensor([18729.6816, 11762.0430, 18777.7520,  ..., 16646.5391, 16747.9141,\n",
      "         9724.0605]) Cost: 5931.693848\n",
      "Epoch 420000/1000000 hypothesis: tensor([18737.6406, 11749.5361, 18786.0918,  ..., 16655.4180, 16756.6992,\n",
      "         9709.2148]) Cost: 5931.077637\n",
      "Epoch 430000/1000000 hypothesis: tensor([18749.0566, 11741.5703, 18797.8887,  ..., 16666.8633, 16768.0449,\n",
      "         9698.6416]) Cost: 5930.517578\n",
      "Epoch 440000/1000000 hypothesis: tensor([18752.4883, 11724.8838, 18801.7461,  ..., 16668.5840, 16769.8770,\n",
      "         9678.5195]) Cost: 5929.995117\n",
      "Epoch 450000/1000000 hypothesis: tensor([18753.2109, 11704.5156, 18802.9219,  ..., 16666.8848, 16768.4023,\n",
      "         9654.2822]) Cost: 5929.481445\n",
      "Epoch 460000/1000000 hypothesis: tensor([18757.2422, 11691.8311, 18807.3438,  ..., 16671.5098, 16772.9941,\n",
      "         9639.7373]) Cost: 5928.986328\n",
      "Epoch 470000/1000000 hypothesis: tensor([18760.2773, 11673.5898, 18810.8633,  ..., 16671.6484, 16773.4922,\n",
      "         9617.4463]) Cost: 5928.514648\n",
      "Epoch 480000/1000000 hypothesis: tensor([18765.1289, 11665.1484, 18816.0977,  ..., 16677.4121, 16779.2539,\n",
      "         9607.8584]) Cost: 5928.085449\n",
      "Epoch 490000/1000000 hypothesis: tensor([18768.8516, 11658.7666, 18820.1953,  ..., 16683.0391, 16784.8691,\n",
      "         9601.3135]) Cost: 5927.688477\n",
      "Epoch 500000/1000000 hypothesis: tensor([18775.1289, 11648.5078, 18826.9473,  ..., 16686.6172, 16788.8398,\n",
      "         9587.8740]) Cost: 5927.306152\n",
      "Epoch 510000/1000000 hypothesis: tensor([18774.9258, 11638.1533, 18827.0977,  ..., 16688.2598, 16790.4180,\n",
      "         9577.2812]) Cost: 5926.932129\n",
      "Epoch 520000/1000000 hypothesis: tensor([18780.0645, 11629.3994, 18832.6309,  ..., 16692.6992, 16794.9297,\n",
      "         9566.5430]) Cost: 5926.570801\n",
      "Epoch 530000/1000000 hypothesis: tensor([18785.3789, 11619.7090, 18838.3965,  ..., 16694.9531, 16797.5117,\n",
      "         9553.7002]) Cost: 5926.233887\n",
      "Epoch 540000/1000000 hypothesis: tensor([18786.6211, 11609.0059, 18840.0723,  ..., 16693.6191, 16796.4258,\n",
      "         9540.5195]) Cost: 5925.921875\n",
      "Epoch 550000/1000000 hypothesis: tensor([18791.2578, 11601.3916, 18845.1641,  ..., 16695.2871, 16798.4434,\n",
      "         9530.2529]) Cost: 5925.618652\n",
      "Epoch 560000/1000000 hypothesis: tensor([18793.6094, 11591.7227, 18847.9746,  ..., 16694.8105, 16798.3242,\n",
      "         9518.0449]) Cost: 5925.316406\n",
      "Epoch 570000/1000000 hypothesis: tensor([18803.2930, 11591.8838, 18858.0820,  ..., 16703.4180, 16807.1680,\n",
      "         9516.8350]) Cost: 5925.021484\n",
      "Epoch 580000/1000000 hypothesis: tensor([18812.2266, 11595.6514, 18867.3867,  ..., 16713.0352, 16816.8223,\n",
      "         9520.6582]) Cost: 5924.761230\n",
      "Epoch 590000/1000000 hypothesis: tensor([18821.1055, 11594.1387, 18876.7305,  ..., 16718.5742, 16822.7891,\n",
      "         9516.6523]) Cost: 5924.499023\n",
      "Epoch 600000/1000000 hypothesis: tensor([18825.2793, 11588.6602, 18881.3613,  ..., 16719.9043, 16824.5371,\n",
      "         9509.0312]) Cost: 5924.235352\n",
      "Epoch 610000/1000000 hypothesis: tensor([18831.8887, 11583.9736, 18888.4570,  ..., 16722.4922, 16827.6680,\n",
      "         9501.4502]) Cost: 5923.972656\n",
      "Epoch 620000/1000000 hypothesis: tensor([18842.9316, 11584.6729, 18899.9727,  ..., 16730.1934, 16835.8477,\n",
      "         9499.6943]) Cost: 5923.726074\n",
      "Epoch 630000/1000000 hypothesis: tensor([18847.2344, 11579.0723, 18904.7559,  ..., 16731.0898, 16837.2715,\n",
      "         9491.7090]) Cost: 5923.469727\n",
      "Epoch 640000/1000000 hypothesis: tensor([18854.4023, 11578.8594, 18912.3809,  ..., 16735.4668, 16842.0996,\n",
      "         9489.7627]) Cost: 5923.239258\n",
      "Epoch 650000/1000000 hypothesis: tensor([18856.5117, 11576.0029, 18914.9082,  ..., 16736.3672, 16843.2793,\n",
      "         9486.2158]) Cost: 5923.010254\n",
      "Epoch 660000/1000000 hypothesis: tensor([18858.7949, 11570.0576, 18917.6523,  ..., 16735.1504, 16842.5410,\n",
      "         9478.0742]) Cost: 5922.765137\n",
      "Epoch 670000/1000000 hypothesis: tensor([18860.8359, 11565.1660, 18920.1309,  ..., 16734.6094, 16842.3770,\n",
      "         9471.5752]) Cost: 5922.528809\n",
      "Epoch 680000/1000000 hypothesis: tensor([18864.2539, 11561.7139, 18924.0098,  ..., 16734.4316, 16842.6836,\n",
      "         9466.1006]) Cost: 5922.295898\n",
      "Epoch 690000/1000000 hypothesis: tensor([18867.1758, 11560.7676, 18927.3516,  ..., 16735.2930, 16843.8672,\n",
      "         9464.2480]) Cost: 5922.079590\n",
      "Epoch 700000/1000000 hypothesis: tensor([18872.5781, 11561.9941, 18933.1680,  ..., 16738.4531, 16847.3125,\n",
      "         9464.4150]) Cost: 5921.866211\n",
      "Epoch 710000/1000000 hypothesis: tensor([18873.2676, 11559.4990, 18934.2539,  ..., 16737.5996, 16846.6953,\n",
      "         9461.3262]) Cost: 5921.648926\n",
      "Epoch 720000/1000000 hypothesis: tensor([18874.0195, 11554.8682, 18935.4395,  ..., 16735.2520, 16844.7363,\n",
      "         9455.0869]) Cost: 5921.420898\n",
      "Epoch 730000/1000000 hypothesis: tensor([18875.8164, 11551.8965, 18937.6582,  ..., 16734.3887, 16844.2188,\n",
      "         9450.7891]) Cost: 5921.200684\n",
      "Epoch 740000/1000000 hypothesis: tensor([18880.5195, 11552.3662, 18942.7578,  ..., 16736.8613, 16846.9355,\n",
      "         9450.1670]) Cost: 5920.992676\n",
      "Epoch 750000/1000000 hypothesis: tensor([18882.8398, 11550.9170, 18945.4785,  ..., 16737.2109, 16847.5117,\n",
      "         9447.8193]) Cost: 5920.780273\n",
      "Epoch 760000/1000000 hypothesis: tensor([18885.7910, 11547.7373, 18948.8574,  ..., 16736.4746, 16847.1328,\n",
      "         9442.6035]) Cost: 5920.555176\n",
      "Epoch 770000/1000000 hypothesis: tensor([18889.3125, 11546.3096, 18952.7773,  ..., 16737.1934, 16848.1328,\n",
      "         9439.7119]) Cost: 5920.343750\n",
      "Epoch 780000/1000000 hypothesis: tensor([18890.9668, 11542.6650, 18954.8379,  ..., 16735.8887, 16847.1289,\n",
      "         9434.4805]) Cost: 5920.126465\n",
      "Epoch 790000/1000000 hypothesis: tensor([18891.6875, 11539.8047, 18955.9414,  ..., 16734.8457, 16846.3066,\n",
      "         9430.8408]) Cost: 5919.917969\n",
      "Epoch 800000/1000000 hypothesis: tensor([18893.7539, 11537.6865, 18958.3945,  ..., 16734.7559, 16846.4375,\n",
      "         9427.6533]) Cost: 5919.708984\n",
      "Epoch 810000/1000000 hypothesis: tensor([18895.1387, 11530.3770, 18960.2285,  ..., 16730.8047, 16842.9922,\n",
      "         9417.1904]) Cost: 5919.475098\n",
      "Epoch 820000/1000000 hypothesis: tensor([18901.9434, 11529.8027, 18967.4707,  ..., 16733.0254, 16845.6523,\n",
      "         9413.9941]) Cost: 5919.261230\n",
      "Epoch 830000/1000000 hypothesis: tensor([18907.5469, 11530.0430, 18973.4805,  ..., 16735.3809, 16848.3164,\n",
      "         9412.5000]) Cost: 5919.054199\n",
      "Epoch 840000/1000000 hypothesis: tensor([18910.7969, 11529.9121, 18977.1172,  ..., 16735.9102, 16849.0859,\n",
      "         9411.1660]) Cost: 5918.848633\n",
      "Epoch 850000/1000000 hypothesis: tensor([18913.5898, 11531.2285, 18980.2754,  ..., 16736.8281, 16850.1484,\n",
      "         9411.9365]) Cost: 5918.648438\n",
      "Epoch 860000/1000000 hypothesis: tensor([18915.0098, 11530.1230, 18982.0801,  ..., 16735.6230, 16849.1699,\n",
      "         9409.8027]) Cost: 5918.440430\n",
      "Epoch 870000/1000000 hypothesis: tensor([18915.9023, 11529.1904, 18983.3438,  ..., 16734.3828, 16848.1113,\n",
      "         9408.1670]) Cost: 5918.233887\n",
      "Epoch 880000/1000000 hypothesis: tensor([18918.5938, 11529.6807, 18986.4141,  ..., 16734.6855, 16848.6055,\n",
      "         9407.7744]) Cost: 5918.030273\n",
      "Epoch 890000/1000000 hypothesis: tensor([18919.5918, 11525.0273, 18987.8398,  ..., 16730.8594, 16845.1992,\n",
      "         9400.6455]) Cost: 5917.803711\n",
      "Epoch 900000/1000000 hypothesis: tensor([18921.7520, 11524.2803, 18990.3848,  ..., 16730.1562, 16844.7129,\n",
      "         9398.6875]) Cost: 5917.595703\n",
      "Epoch 910000/1000000 hypothesis: tensor([18923.8750, 11520.2520, 18992.9336,  ..., 16727.0801, 16842.0410,\n",
      "         9391.9111]) Cost: 5917.371582\n",
      "Epoch 920000/1000000 hypothesis: tensor([18928.4844, 11524.7041, 18997.8613,  ..., 16730.8340, 16845.7656,\n",
      "         9396.4141]) Cost: 5917.182617\n",
      "Epoch 930000/1000000 hypothesis: tensor([18932.1953, 11524.9912, 19001.9473,  ..., 16731.3848, 16846.4922,\n",
      "         9395.2363]) Cost: 5916.977051\n",
      "Epoch 940000/1000000 hypothesis: tensor([18937.7617, 11526.0869, 19007.9023,  ..., 16733.0410, 16848.4102,\n",
      "         9394.3896]) Cost: 5916.770508\n",
      "Epoch 950000/1000000 hypothesis: tensor([18942.6094, 11530.8750, 19013.0684,  ..., 16736.9609, 16852.2930,\n",
      "         9399.2021]) Cost: 5916.584961\n",
      "Epoch 960000/1000000 hypothesis: tensor([18944.0820, 11527.7148, 19014.9355,  ..., 16734.2207, 16849.8320,\n",
      "         9393.9346]) Cost: 5916.367188\n",
      "Epoch 970000/1000000 hypothesis: tensor([18946.3438, 11526.7637, 19017.5566,  ..., 16733.4980, 16849.2422,\n",
      "         9391.6094]) Cost: 5916.158691\n",
      "Epoch 980000/1000000 hypothesis: tensor([18948.0176, 11526.0098, 19019.5781,  ..., 16732.7344, 16848.5840,\n",
      "         9389.8564]) Cost: 5915.955566\n",
      "Epoch 990000/1000000 hypothesis: tensor([18950.6074, 11524.5439, 19022.5391,  ..., 16731.7246, 16847.8164,\n",
      "         9386.6465]) Cost: 5915.749512\n",
      "Epoch 1000000/1000000 hypothesis: tensor([18953.2578, 11523.6943, 19025.5566,  ..., 16731.1699, 16847.4688,\n",
      "         9384.3096]) Cost: 5915.546387\n"
     ]
    }
   ],
   "source": [
    "W = torch.zeros((9, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.00001)\n",
    "\n",
    "nb_epochs = 1000000\n",
    "\n",
    "#     # cost 계산\n",
    "\n",
    "# cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "# cost = torch.abs(hypothesis - y_train).sum()\n",
    "# cost\n",
    "\n",
    "mae = torch.nn.L1Loss()\n",
    "    \n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    # Matrix 연산!!\n",
    "    hypothesis = x_train.matmul(W) + b # or .mm or @\n",
    "\n",
    "    # cost 계산\n",
    "   \n",
    "\n",
    "    cost = mae(hypothesis, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    \n",
    "    if epoch %10000==0:\n",
    "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()))# 모델 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b19ca87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:48:39.365441Z",
     "iopub.status.busy": "2022-09-18T02:48:39.363803Z",
     "iopub.status.idle": "2022-09-18T02:48:39.371382Z",
     "shell.execute_reply": "2022-09-18T02:48:39.370364Z"
    },
    "papermill": {
     "duration": 0.018717,
     "end_time": "2022-09-18T02:48:39.373503",
     "exception": false,
     "start_time": "2022-09-18T02:48:39.354786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16831, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = x_test.matmul(W) + b \n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10dbc729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:48:39.390255Z",
     "iopub.status.busy": "2022-09-18T02:48:39.389995Z",
     "iopub.status.idle": "2022-09-18T02:48:39.396889Z",
     "shell.execute_reply": "2022-09-18T02:48:39.395950Z"
    },
    "papermill": {
     "duration": 0.017429,
     "end_time": "2022-09-18T02:48:39.398785",
     "exception": false,
     "start_time": "2022-09-18T02:48:39.381356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17802.9004],\n",
       "        [13191.1572],\n",
       "        [17038.5547],\n",
       "        ...,\n",
       "        [13777.0156],\n",
       "        [17458.4199],\n",
       "        [10501.2090]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f45c378f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T02:48:39.416233Z",
     "iopub.status.busy": "2022-09-18T02:48:39.415454Z",
     "iopub.status.idle": "2022-09-18T02:48:39.457568Z",
     "shell.execute_reply": "2022-09-18T02:48:39.456757Z"
    },
    "papermill": {
     "duration": 0.05268,
     "end_time": "2022-09-18T02:48:39.459355",
     "exception": false,
     "start_time": "2022-09-18T02:48:39.406675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame()\n",
    "\n",
    "submit['ID'] = pd.Series(range(len(y_pred)))\n",
    "submit['price'] = y_pred.detach().numpy()\n",
    "submit.to_csv('submit.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 382.331349,
   "end_time": "2022-09-18T02:48:40.389768",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-18T02:42:18.058419",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
